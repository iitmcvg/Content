{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOUGH TRANSFORMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Line Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "#### Hough Transform is a popular technique to detect any shape, if you can represent that shape in mathematical form. It can detect the shape even if it is broken or distorted a little bit. We will see how it works for a line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line can be represented as ğ‘¦ = ğ‘šğ‘¥ + ğ‘ or in parametric form, as ğœŒ = ğ‘¥ cos ğœƒ + ğ‘¦ sin ğœƒ where ğœŒ is the perpendicular distance from origin to the line, and ğœƒ is the angle formed by this perpendicular line and horizontal axis measured in counter-clockwise ( That direction varies on how you represent the coordinate system. This representation is used in OpenCV). Check below image:\n",
    "\n",
    "<img src = houghlines1.svg>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if line is passing below the origin, it will have a positive rho and angle less than 180. If it is going above the origin, instead of taking angle greater than 180, angle is taken less than 180, and rho is taken negative. Any vertical line will have 0 degree and horizontal lines will have 90 degree.\n",
    "\n",
    "Now letâ€™s see how Hough Transform works for lines. Any line can be represented in these two terms, (ğœŒ, ğœƒ). So first it creates a 2D array or accumulator (to hold values of two parameters) and it is set to 0 initially. Let rows denote the ğœŒ and columns denote the ğœƒ. Size of array depends on the accuracy you need. Suppose you want the accuracy of angles to be 1 degree, you need 180 columns. For ğœŒ, the maximum distance possible is the diagonal length of the image. So taking one pixel accuracy, number of rows can be diagonal length of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a 100x100 image with a horizontal line at the middle. Take the first point of the line. You know its (x,y) values. Now in the line equation, put the values ğœƒ = 0, 1, 2, ...., 180 and check the ğœŒ you get. For every (ğœŒ, ğœƒ) pair, you increment value by one in our accumulator in its corresponding (ğœŒ, ğœƒ) cells. So now in accumulator, the cell (50,90) = 1 along with some other cells.\n",
    "\n",
    "Now take the second point on the line. Do the same as above. Increment the the values in the cells corresponding to (ğœŒ, ğœƒ) you got. This time, the cell (50,90) = 2. What you actually do is voting the (ğœŒ, ğœƒ) values. You continue this process for every point on the line. At each point, the cell (50,90) will be incremented or voted up, while other cells may or may not be voted up. This way, at the end, the cell (50,90) will have maximum votes. So if you search the accumulator for maximum votes, you get the value (50,90) which says, there is a line in this image at distance 50 from origin and at angle 90 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out this cool animation:\n",
    "http://docs.opencv.org/3.0-beta/_images/houghlinesdemo.gif\n",
    "\n",
    "<img src = houghlinesdemo.gif>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how hough transform for lines works. It is simple, and may be you can implement it using Numpy on your own. Below is an image which shows the accumulator. Bright spots at some locations denotes they are the parameters of possible lines in the image.\n",
    "\n",
    "<img src = houghlines2.jpg>\n",
    "\n",
    "## Now Let us Check out the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the image here:\n",
    "Image is attached in the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('sudoku.jpg')\n",
    "img2=img.copy()\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To apply Hough Line Transform, the image must be binary. So, we either threshold or apply Canny Edge detector to the image:\n",
    "#### We have used Canny edge detector here. Try using thresholding. For details about thresholding look into the respective tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In OpenCV,\n",
    "##### cv2.HoughLines( )\n",
    "performs the hough line transform as illustrated above.\n",
    "\n",
    "It simply returns an array of (ğœŒ, ğœƒ) values. ğœŒ is measured in pixels and ğœƒ is measured in radians.\n",
    "\n",
    "##### Its, parameters are:\n",
    "\n",
    "First parameter, Input image should be a binary image, so we pass the thresholded or edge detected image.\n",
    "\n",
    "Second and third parameters are ğœŒ and ğœƒ accuracies respectively.\n",
    "\n",
    "##### Fourth argument is the threshold, which means minimum vote it should get for it to be considered as a line. Remember, number of votes depend upon number of points on the line. So it represents the minimum length of line that should be detected.\n",
    "\n",
    "##### Pass the image. ğœŒ accuracy is a natural number. ğœƒ accuracy is in radians. Threshold is a natural number(set it high to avoid false lines). Pass the required parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines=cv2.HoughLines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: lines[0] is an array storing r and theta values for different lines detected in the image\n",
    "We have drawn the detected lines extending to a distance of 1000 above and below the given coordinates( ğœŒ * cos(ğœƒ) , ğœŒ * sin(ğœƒ))\n",
    "\n",
    "#### Pass correct values for x1,x2,y1,y2 to complete a line. And using cv2.line( ), draw the lines passing the image where line has to be drawn, x1,y1,  x2, y2, colour of line (list of 3 integers representing BGR) and thickness.\n",
    "\n",
    "### EXECUTE THE MARKDOWN CELL BELOW THE CODE CELL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = \n",
    "    y1 = \n",
    "    x2 = \n",
    "    y2 =\n",
    "\n",
    "\n",
    "    cv2.line()\n",
    "cv2.imwrite('houghlines.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUT:\n",
    "<img src = 'houghlines.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Hough Line Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the hough transform, you can see that even for a line with two arguments, it takes a lot of computation. Probabilistic Hough Transform is an optimization of Hough Transform we saw. It doesnâ€™t take all the points into consideration, instead take only a random subset of points and that is sufficient for line detection. Just we have to decrease the threshold. See below image which compare Hough Transform and Probabilistic Hough Transform in hough space.\n",
    "\n",
    "This image illustrates Probabilistic Hough Transform better:\n",
    "<img src = houghlines4.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The function used is cv2.HoughLinesP(). It has two new arguments.\n",
    "\n",
    "minLineLength - Minimum length of line. Line segments shorter than this are rejected.\n",
    "\n",
    "maxLineGap - Maximum allowed gap between line segments to treat them as single line.\n",
    "\n",
    "##### PLEASE NOTE THAT THE THRESHOLD FOR Probabilistic Hough Transform is LOWER. Pass the first 4 parameters as in cv2.HoughLines( ). Pass values to minLineLength and maxLineGap. Both are natural numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minLineLength = \n",
    "maxLineGap = \n",
    "linesP = cv2.HoughLinesP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best thing is that, it directly returns the two endpoints of lines. In previous case, you got only the parameters of lines, and you had to find all the points. Here, everything is direct and simple. \n",
    "#### Fill in cv2.line() with the correct parameters to draw a line of a desired colour and thickness. Pass img2 to avoid overlap of lines from the previous transform.\n",
    "\n",
    "### EXECUTE THE MARKDOWN CELL BELOW THIS CODE CELL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x1,y1,x2,y2 in linesP[0]:\n",
    "    cv2.line()\n",
    "\n",
    "cv2.imwrite('houghlinesP.jpg',img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUT:\n",
    "<img src = 'houghlinesP.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOUGH CIRCLE TRANSFORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar to a line, a circle can be represented using certain parameters. This drives us towards a transform for an image to detect circles in it.\n",
    "\n",
    "#### A circle is represented mathematically as (ğ‘¥ âˆ’ ğ‘¥ğ‘ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘Ÿ )2 + (ğ‘¦ âˆ’ ğ‘¦ğ‘ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘Ÿ )2 = ğ‘Ÿ2 where (ğ‘¥ğ‘ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘Ÿ , ğ‘¦ğ‘ğ‘’ğ‘›ğ‘¡ğ‘’ğ‘Ÿ ) is the center of the circle, and ğ‘Ÿ is the radius of the circle. From equation, we can see we have 3 parameters. So we need a 3D accumulator for hough transform, which would be highly ineffective. So OpenCV uses more trickier method, Hough Gradient Method which uses the gradient information of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we move on to the code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the image here (preferably an image with circles) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cimg = cv2.imread('opencv.png')\n",
    "img_circ = cv2.cvtColor(cimg,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### We blur the image for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_circ = cv2.medianBlur(img_circ,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Complete the function to detect circles in the image.\n",
    "##### The parameters are as follows:\n",
    "##### Parameters:\t\n",
    "###### image â€“ 8-bit, single-channel, grayscale input image. Hence, use img_circ\n",
    "###### method â€“ Detection method to use. Currently, the only implemented method is CV_HOUGH_GRADIENT \n",
    "###### dp â€“ Inverse ratio of the accumulator resolution to the image resolution. For example, if dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has half as big width and height.\n",
    "###### minDist â€“ Minimum distance between the centers of the detected circles. If the parameter is too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is too large, some circles may be missed.\n",
    "###### param1 â€“ First method-specific parameter. In case of CV_HOUGH_GRADIENT , it is the higher threshold of the two passed to the Canny() edge detector used in this method (the lower one is twice smaller). PLEASE CHECK OUT EDGE DETECTION TUTORIAL FOR MORE DETAILS.\n",
    "###### param2 â€“ Second method-specific parameter. In case of CV_HOUGH_GRADIENT , it is the accumulator threshold for the circle centers at the detection stage. The smaller it is, the more false circles may be detected. Circles, corresponding to the larger accumulator values, will be returned first.\n",
    "###### minRadius â€“ Minimum circle radius.\n",
    "###### maxRadius â€“ Maximum circle radius.\n",
    "\n",
    "##### Returns:\n",
    "###### circles â€“ Output vector of found circles. Each vector is encoded as a 3-element floating-point vector (x, y, radius) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "circles = cv2.HoughCircles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using np.around(), we round off array of (x,y,radius) to the nearest integer\n",
    "\n",
    "#### Use cv2.circle( ) and draw the detected circles. You need to pass cimg, (x_centre,y_centre), radius, colour of circle(list of 3 integers representing the colour), thickness of circle\n",
    "#### Again using cv2.circle( ), plot the centres in cimg. Again we need to pass cimg, (x_centre,y_centre), hardcoded radius of point(very small), colour of point, thickness of drawn circle around point(-1 for filling the complete point)\n",
    "### EXECUTE THE MARKDOWN CELL BELOW THIS CODE CELL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle() \n",
    "    # draw the center of the circle \n",
    "    cv2.circle()\n",
    "    cv2.imwrite('detected_circles.jpg',cimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUT:\n",
    "<img src='detected_circles.jpg'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
